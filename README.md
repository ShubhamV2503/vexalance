# vexalance# ğŸ¤– AI Coding Assistant with API Testing (Streamlit + Ollama + Postman 

This project is an **AI-powered coding assistant** built using **Streamlit**, **Ollama**, and **Postman (Newman)** to help developers generate backend APIs, edit them, and test them â€” all in one unified interface.

---

## ğŸ”¥ Features

### ğŸ§  AI Code Assistant
- Powered by [Ollama](https://ollama.com/) and local models like `codellama`.
- Streamlines natural language prompts into production-ready FastAPI code.
- Extracts and lists all API endpoints from the generated code.

### âœï¸ Editable Endpoints
- View and edit auto-extracted API endpoints (e.g., `GET /users`, `POST /users/{id}`).
- Override HTTP methods and modify routes directly within the UI.

### ğŸ“¦ Request Configuration
- Input custom headers and body as JSON.
- Flexible enough for any API interaction.

### ğŸš€ One-Click API Testing
- Converts extracted endpoints into a Postman Collection.
- Uses Docker to run **Newman** tests on your local FastAPI app.
- View the full test output (success/failure and response) inline.

---

## ğŸ§± Tech Stack

| Tool        | Role                                  |
|-------------|---------------------------------------|
| Streamlit   | Interactive frontend                  |
| Ollama      | Local LLM serving via REST API        |
| codellama   | Code generation model                 |
| Postman     | API structure standard                |
| Newman      | API testing CLI (Dockerized)          |
| Docker      | Container runtime for Newman          |
| Python      | Backend logic + Streamlit integration |


â¸»


## âš™ï¸ Setup Commands

### ğŸ”§ 1. Install Required Python Packages

```bash
pip install streamlit httpx


â¸»

ğŸš€ 2. Start the Ollama Model Server

ollama run codellama

âš ï¸ Keep this running in a separate terminal.
This starts the local API server at http://localhost:11434.

â¸»

ğŸ³ 3. Pull the Postman Newman Docker Image

docker pull postman/newman

Used for API testing via collection.json

â¸»

ğŸ’» 4. Run the FastAPI App (Optional - If Code Uses FastAPI)

uvicorn main:app --reload

Replace main with the filename containing your generated code (e.g., main.py).

â¸»

ğŸŒ 5. Run the Streamlit App

streamlit run app.py

This launches the full AI assistant and API testing interface in your browser.

â¸»

ğŸ§ª Usage Flow
	1.	Enter a natural language prompt like:

Create a FastAPI with CRUD operations for products.


	2.	The AI will:
	â€¢	Generate real-time FastAPI code.
	â€¢	Extract endpoints like GET /products, POST /products, etc.
	3.	You can:
	â€¢	Edit any endpoint inline.
	â€¢	Enter headers & request body as JSON.
	â€¢	Click Test API Collection.
	4.	Newman (in Docker) will:
	â€¢	Test the endpoints live.
	â€¢	Show success/fail status and logs right inside the app.

â¸»
